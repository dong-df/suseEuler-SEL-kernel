From 8d1faee57910c6150f38f43a9e72ba87e724e819 Mon Sep 17 00:00:00 2001
From: Chen Wandun <chenwandun@huawei.com>
Date: Wed, 23 Feb 2022 18:45:23 +0800
Subject: [PATCH] mm: add support for page cache use reliable memory
Patch-mainline: Not yet, from openEuler
References: bsn#22
openEuler-commit: 8d1faee57910c6150f38f43a9e72ba87e724e819
Modified-by-SEL: No


hulk inclusion
category: feature
bugzilla: https://gitee.com/openeuler/kernel/issues/I4PM0Z
CVE: NA

--------------------------------

__page_cache_alloc is used to alloc page cache in most file system,
such as ext4, f2fs, so add GFP_RELIABLE flag to use reliable
memory when alloc page cache.

Signed-off-by: Chen Wandun <chenwandun@huawei.com>
Reviewed-by: Kefeng Wang <wangkefeng.wang@huawei.com>
Signed-off-by: Zheng Zengkai <zhengzengkai@huawei.com>
Signed-off-by: Guoqing Jiang <guoqing.jiang@suse.com>
---
 include/linux/mem_reliable.h | 2 ++
 mm/filemap.c                 | 2 ++
 mm/mem_reliable.c            | 6 ++++++
 3 files changed, 10 insertions(+)

diff --git a/include/linux/mem_reliable.h b/include/linux/mem_reliable.h
index 8f858d11ce6f..38891cb2fa83 100644
--- a/include/linux/mem_reliable.h
+++ b/include/linux/mem_reliable.h
@@ -20,6 +20,7 @@ extern void mem_reliable_init(bool has_unmirrored_mem,
 			      unsigned long *zone_movable_pfn);
 extern void shmem_reliable_init(void);
 extern void reliable_report_meminfo(struct seq_file *m);
+extern void page_cache_prepare_alloc(gfp_t *gfp);
 
 static inline bool mem_reliable_is_enabled(void)
 {
@@ -68,6 +69,7 @@ static inline bool skip_none_movable_zone(gfp_t gfp, struct zoneref *z)
 }
 static inline void reliable_report_meminfo(struct seq_file *m) {}
 static inline bool shmem_reliable_is_enabled(void) { return false; }
+static inline void page_cache_prepare_alloc(gfp_t *gfp) {}
 #endif
 
 #endif
diff --git a/mm/filemap.c b/mm/filemap.c
index f9e4760b9cbd..3958fc3280d8 100644
--- a/mm/filemap.c
+++ b/mm/filemap.c
@@ -954,6 +954,8 @@ struct page *__page_cache_alloc(gfp_t gfp)
 	int n;
 	struct page *page;
 
+	page_cache_prepare_alloc(&gfp);
+
 	if (cpuset_do_page_mem_spread()) {
 		unsigned int cpuset_mems_cookie;
 		do {
diff --git a/mm/mem_reliable.c b/mm/mem_reliable.c
index e977a4122f8a..b1bc749532a4 100644
--- a/mm/mem_reliable.c
+++ b/mm/mem_reliable.c
@@ -15,6 +15,12 @@ bool reliable_enabled;
 static atomic_long_t total_reliable_mem;
 bool shmem_reliable __read_mostly = true;
 
+void page_cache_prepare_alloc(gfp_t *gfp)
+{
+	if (mem_reliable_is_enabled())
+		*gfp |= GFP_RELIABLE;
+}
+
 void add_reliable_mem_size(long sz)
 {
 	atomic_long_add(sz, &total_reliable_mem);
-- 
2.26.2

