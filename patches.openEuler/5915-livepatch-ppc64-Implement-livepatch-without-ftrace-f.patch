From ac81d625f3dac7a9b6b811c6b36c46502a3e2d60 Mon Sep 17 00:00:00 2001
From: Cheng Jian <cj.chengjian@huawei.com>
Date: Sat, 29 May 2021 14:43:03 +0800
Subject: [PATCH] livepatch/ppc64: Implement livepatch without ftrace for
Patch-mainline: Not yet, from openEuler
References: bsn#22
openEuler-commit: ac81d625f3dac7a9b6b811c6b36c46502a3e2d60

 ppc64be

hulk inclusion
category: feature
bugzilla: 51924
CVE: NA

---------------------------

Initially completed the livepatch for ppc64be, the call from
the old function to the new function, using stub space, this
is actually problematic, because we cannot effectively recover
R2. This problem will be fixed later.

Signed-off-by: Cheng Jian <cj.chengjian@huawei.com>
Reviewed-By: Xie XiuQi <xiexiuqi@huawei.com>
Signed-off-by: yangerkun <yangerkun@huawei.com>

Signed-off-by: Dong Kai <dongkai11@huawei.com>

Signed-off-by: Ye Weihua <yeweihua4@huawei.com>
Reviewed-by: Kuohai Xu <xukuohai@huawei.com>
Reviewed-by: Yang Jihong <yangjihong1@huawei.com>
Signed-off-by: Zheng Zengkai <zhengzengkai@huawei.com>
Signed-off-by: Guoqing Jiang <guoqing.jiang@suse.com>
---
 arch/powerpc/include/asm/module.h  |  10 +
 arch/powerpc/kernel/livepatch_64.c | 325 +++++++++++++++++++++++++++++
 arch/powerpc/kernel/module_64.c    |  38 ++++
 include/linux/livepatch.h          |   3 +
 kernel/livepatch/core.c            |   6 +
 5 files changed, 382 insertions(+)
 create mode 100644 arch/powerpc/kernel/livepatch_64.c

diff --git a/arch/powerpc/include/asm/module.h b/arch/powerpc/include/asm/module.h
index 857d9ff24295..993ff68c1308 100644
--- a/arch/powerpc/include/asm/module.h
+++ b/arch/powerpc/include/asm/module.h
@@ -33,6 +33,9 @@ struct mod_arch_specific {
 	/* For module function descriptor dereference */
 	unsigned long start_opd;
 	unsigned long end_opd;
+#ifdef CONFIG_LIVEPATCH_WO_FTRACE
+	unsigned long toc;
+#endif
 #else /* powerpc64 */
 	/* Indices of PLT sections within module. */
 	unsigned int core_plt_section;
@@ -83,5 +86,12 @@ static inline int module_finalize_ftrace(struct module *mod, const Elf_Shdr *sec
 }
 #endif
 
+#ifdef CONFIG_LIVEPATCH_WO_FTRACE
+struct ppc64_stub_entry;
+int livepatch_create_stub(struct ppc64_stub_entry *entry,
+			  unsigned long addr,
+			  struct module *me);
+#endif
+
 #endif /* __KERNEL__ */
 #endif	/* _ASM_POWERPC_MODULE_H */
diff --git a/arch/powerpc/kernel/livepatch_64.c b/arch/powerpc/kernel/livepatch_64.c
new file mode 100644
index 000000000000..f9481057b2bb
--- /dev/null
+++ b/arch/powerpc/kernel/livepatch_64.c
@@ -0,0 +1,325 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
+/*
+ * livepatch.c - powerpc-specific Kernel Live Patching Core
+ *
+ * Copyright (C) 2018  Huawei Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, see <http://www.gnu.org/licenses/>.
+ */
+
+#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
+
+#include <linux/module.h>
+#include <linux/uaccess.h>
+#include <linux/livepatch.h>
+#include <linux/slab.h>
+#include <linux/sizes.h>
+#include <linux/kallsyms.h>
+#include <linux/sched/debug.h>
+
+#include <asm/livepatch.h>
+#include <asm/cacheflush.h>
+#include <asm/code-patching.h>
+#include <asm/elf.h>
+
+/*
+ * see struct ppc64_stub_entry
+ *
+ * u32 jump[7] :
+ *	addis   r11,r2, <high>
+ *	addi    r11,r11, <low>
+ *	; Save current r2 value in magic place on the stack
+ *	std     r2,R2_STACK_OFFSET(r1)
+ *	ld      r12,32(r11)
+ *	; Set up new r2 from function descriptor, only for ABI V1
+ *	ld      r2,40(r11)
+ *	mtctr   r12
+ *	bctr
+ * u32 unused  :
+ *	XXXX;	no changed here
+ * func_desc_t funcdata :
+ *	ulong	funcaddr;
+ *	ulong	r2;
+ */
+#define LJMP_INSN_SIZE	12
+
+#ifdef CONFIG_LIVEPATCH_STOP_MACHINE_CONSISTENCY
+struct stackframe {
+	unsigned long sp;
+	unsigned long pc;
+};
+
+struct walk_stackframe_args {
+	struct klp_patch *patch;
+	int enable;
+	int ret;
+};
+
+static inline int klp_compare_address(unsigned long pc,
+				      unsigned long func_addr,
+				      unsigned long func_size,
+				      const char *func_name)
+{
+	if (pc >= func_addr && pc < func_addr + func_size) {
+		pr_err("func %s is in use!\n", func_name);
+		return -EBUSY;
+	}
+	return 0;
+}
+
+static int klp_check_activeness_func(struct stackframe *frame, void *data)
+{
+	struct walk_stackframe_args *args = data;
+	struct klp_patch *patch = args->patch;
+	struct klp_object *obj;
+	struct klp_func *func;
+	unsigned long func_addr, func_size;
+	const char *func_name;
+
+	if (args->ret)
+		return args->ret;
+
+	for (obj = patch->objs; obj->funcs; obj++) {
+		for (func = obj->funcs; func->old_name; func++) {
+			if (args->enable) {
+				func_addr = (unsigned long)func->old_func;
+				func_size = func->old_size;
+			} else {
+				func_addr = (unsigned long)func->new_func;
+				func_size = func->new_size;
+			}
+			func_name = func->old_name;
+			args->ret = klp_compare_address(frame->pc, func_addr,
+					func_size, func_name);
+			if (args->ret)
+				return args->ret;
+		}
+	}
+
+	return args->ret;
+}
+
+static int unwind_frame(struct task_struct *tsk, struct stackframe *frame)
+{
+
+	unsigned long *stack;
+
+	if (!validate_sp(frame->sp, tsk, STACK_FRAME_OVERHEAD))
+		return -1;
+
+	stack = (unsigned long *)frame->sp;
+	frame->sp = stack[0];
+	frame->pc = stack[STACK_FRAME_LR_SAVE];
+#ifdef CONFIG_FUNCTION_GRAPH_TRACE
+	/*
+	 * IMHO these tests do not belong in
+	 * arch-dependent code, they are generic.
+	 */
+	frame->pc = ftrace_graph_ret_addr(tsk, &ftrace_idx, frame->ip, stack);
+#endif
+
+	return 0;
+}
+
+static void notrace klp_walk_stackframe(struct stackframe *frame,
+		int (*fn)(struct stackframe *, void *),
+		struct task_struct *tsk, void *data)
+{
+	while (1) {
+		int ret;
+
+		if (fn(frame, data))
+			break;
+		ret = unwind_frame(tsk, frame);
+		if (ret < 0)
+			break;
+	}
+}
+
+int klp_check_calltrace(struct klp_patch *patch, int enable)
+{
+	struct task_struct *g, *t;
+	struct stackframe frame;
+	unsigned long *stack;
+	int ret = 0;
+
+	struct walk_stackframe_args args = {
+		.patch = patch,
+		.enable = enable,
+		.ret = 0
+	};
+
+	for_each_process_thread(g, t) {
+		if (t == current) {
+			/*
+			 * Handle the current carefully on each CPUs,
+			 * we shouldn't use saved FP and PC when
+			 * backtrace current. It's difficult to
+			 * backtrack other CPU currents here. But
+			 * fortunately,all CPUs will stay in this
+			 * function, so the current's backtrace is
+			 * so similar
+			 */
+			stack = (unsigned long *)current_stack_pointer;
+		} else if (strncmp(t->comm, "migration/", 10) == 0) {
+			/*
+			 * current on other CPU
+			 * we call this in stop_machine, so the current
+			 * of each CPUs is mirgation, just compare the
+			 * task_comm here, because we can't get the
+			 * cpu_curr(task_cpu(t))). This assumes that no
+			 * other thread will pretend to be a stopper via
+			 * task_comm.
+			 */
+			continue;
+		} else {
+			stack = (unsigned long *)t->thread.ksp;
+		}
+
+		frame.sp = (unsigned long)stack;
+		frame.pc = stack[STACK_FRAME_LR_SAVE];
+		klp_walk_stackframe(&frame, klp_check_activeness_func,
+				t, &args);
+		if (args.ret) {
+			ret = args.ret;
+			pr_info("PID: %d Comm: %.20s\n", t->pid, t->comm);
+			show_stack(t, NULL, KERN_INFO);
+			goto out;
+		}
+	}
+
+out:
+	return ret;
+}
+#endif
+
+#ifdef CONFIG_LIVEPATCH_WO_FTRACE
+struct klp_func_node {
+	struct list_head node;
+	struct list_head func_stack;
+	void *old_func;
+	u32	old_insns[LJMP_INSN_SIZE];
+};
+
+static LIST_HEAD(klp_func_list);
+
+static struct klp_func_node *klp_find_func_node(void *old_func)
+{
+	struct klp_func_node *func_node;
+
+	list_for_each_entry(func_node, &klp_func_list, node) {
+		if (func_node->old_func == old_func)
+			return func_node;
+	}
+
+	return NULL;
+}
+
+int arch_klp_patch_func(struct klp_func *func)
+{
+	struct klp_func_node *func_node;
+	unsigned long pc, new_addr;
+	int i;
+	int memory_flag = 0;
+	long ret;
+
+	func_node = klp_find_func_node(func->old_func);
+	if (!func_node) {
+		func_node = kzalloc(sizeof(*func_node), GFP_ATOMIC);
+		if (!func_node)
+			return -ENOMEM;
+
+		memory_flag = 1;
+		INIT_LIST_HEAD(&func_node->func_stack);
+		func_node->old_func = func->old_func;
+		for (i = 0; i < LJMP_INSN_SIZE; i++) {
+			ret = copy_from_kernel_nofault(&func_node->old_insns[i],
+				((u32 *)func->old_func) + i, 4);
+			if (ret) {
+				kfree(func_node);
+				return -EPERM;
+			}
+		}
+		list_add_rcu(&func_node->node, &klp_func_list);
+	}
+
+	list_add_rcu(&func->stack_node, &func_node->func_stack);
+
+	pc = (unsigned long)func->old_func;
+	new_addr = (unsigned long)func->new_func;
+
+	ret = livepatch_create_stub((struct ppc64_stub_entry *)pc,
+			new_addr, func->old_mod, true);
+	if (ret)
+		goto ERR_OUT;
+
+	return 0;
+
+ERR_OUT:
+	list_del_rcu(&func->stack_node);
+	if (memory_flag) {
+		list_del_rcu(&func_node->node);
+		kfree(func_node);
+	}
+
+	return -EPERM;
+}
+
+void arch_klp_unpatch_func(struct klp_func *func)
+{
+	struct klp_func_node *func_node;
+	struct klp_func *next_func;
+	unsigned long pc, new_addr;
+	u32 insns[LJMP_INSN_SIZE];
+	int i;
+
+	func_node = klp_find_func_node(func->old_func);
+	pc = (unsigned long)func_node->old_func;
+	if (list_is_singular(&func_node->func_stack)) {
+		for (i = 0; i < LJMP_INSN_SIZE; i++)
+			insns[i] = func_node->old_insns[i];
+
+		list_del_rcu(&func->stack_node);
+		list_del_rcu(&func_node->node);
+		kfree(func_node);
+
+		for (i = 0; i < LJMP_INSN_SIZE; i++)
+			patch_instruction((struct ppc_inst *)((u32 *)pc + i),
+					  ppc_inst(insns[i]));
+	} else {
+		list_del_rcu(&func->stack_node);
+		next_func = list_first_or_null_rcu(&func_node->func_stack,
+					struct klp_func, stack_node);
+		new_addr = (unsigned long)next_func->new_func;
+
+		livepatch_create_stub((struct ppc64_stub_entry *)pc,
+			new_addr, func->old_mod, NULL);
+	}
+}
+
+/* return 0 if the func can be patched */
+int arch_klp_func_can_patch(struct klp_func *func)
+{
+	unsigned long old_size = func->old_size;
+
+	if (!old_size)
+		return -EINVAL;
+
+	if (old_size < LJMP_INSN_SIZE * sizeof(u32)) {
+		pr_err("func %s size less than limit\n", func->old_name);
+		return -EPERM;
+	}
+	return 0;
+}
+#endif
diff --git a/arch/powerpc/kernel/module_64.c b/arch/powerpc/kernel/module_64.c
index ae2b188365b1..7ade837f9468 100644
--- a/arch/powerpc/kernel/module_64.c
+++ b/arch/powerpc/kernel/module_64.c
@@ -738,6 +738,9 @@ int apply_relocate_add(Elf64_Shdr *sechdrs,
 		}
 	}
 
+#ifdef CONFIG_LIVEPATCH_WO_FTRACE
+	me->arch.toc = my_r2(sechdrs, me);
+#endif
 	return 0;
 }
 
@@ -799,3 +802,38 @@ int module_finalize_ftrace(struct module *mod, const Elf_Shdr *sechdrs)
 	return 0;
 }
 #endif
+
+#ifdef CONFIG_LIVEPATCH_WO_FTRACE
+#include <asm/livepatch.h>
+#include <asm/cacheflush.h>
+
+/*
+ * Patch stub to reference function and correct r2 value.
+ * see create_stub
+ */
+int livepatch_create_stub(struct ppc64_stub_entry *entry,
+			  unsigned long addr,
+			  struct module *me)
+{
+	long reladdr;
+	unsigned long my_r2 = me ? me->arch.toc : kernel_toc_addr();
+
+	memcpy(entry->jump, ppc64_stub_insns, sizeof(ppc64_stub_insns));
+
+	/* Stub uses address relative to r2. */
+	reladdr = (unsigned long)entry - my_r2;
+	if (reladdr > 0x7FFFFFFF || reladdr < -(0x80000000L)) {
+		pr_err("%s: Address %p of stub out of range of %p.\n",
+		       me->name, (void *)reladdr, (void *)my_r2);
+		return 0;
+	}
+
+	pr_debug("Stub %p get data from reladdr 0x%lx\n", entry, reladdr);
+
+	entry->jump[0] |= PPC_HA(reladdr);
+	entry->jump[1] |= PPC_LO(reladdr);
+	entry->funcdata = func_desc(addr);
+
+	return 1;
+}
+#endif
diff --git a/include/linux/livepatch.h b/include/linux/livepatch.h
index 92f85e6d18f8..c4bc08a3f7f0 100644
--- a/include/linux/livepatch.h
+++ b/include/linux/livepatch.h
@@ -78,6 +78,9 @@ struct klp_func {
 #ifdef CONFIG_LIVEPATCH_PER_TASK_CONSISTENCY
 	bool transition;
 #endif
+#if defined(CONFIG_LIVEPATCH_WO_FTRACE) && defined(CONFIG_PPC64)
+	struct module *old_mod;
+#endif
 };
 
 struct klp_object;
diff --git a/kernel/livepatch/core.c b/kernel/livepatch/core.c
index b1b29efb3e5a..2b1842aac2f8 100644
--- a/kernel/livepatch/core.c
+++ b/kernel/livepatch/core.c
@@ -920,6 +920,12 @@ static int klp_init_func(struct klp_object *obj, struct klp_func *func)
 	func->patched = false;
 
 #ifdef CONFIG_LIVEPATCH_WO_FTRACE
+#ifdef CONFIG_PPC64
+	if (klp_is_module(obj))
+		func->old_mod = obj->mod;
+	else
+		func->old_mod = NULL;
+#endif
 	ret = arch_klp_func_can_patch(func);
 	if (ret)
 		return ret;
-- 
2.26.2

