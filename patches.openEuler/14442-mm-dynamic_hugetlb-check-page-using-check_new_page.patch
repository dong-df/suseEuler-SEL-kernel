From 94974bb002bd8f035e2ed2769757e3aba8d29e32 Mon Sep 17 00:00:00 2001
From: Liu Shixin <liushixin2@huawei.com>
Date: Sun, 20 Mar 2022 10:48:17 +0800
Subject: [PATCH] mm/dynamic_hugetlb: check page using check_new_page
Patch-mainline: Not yet, from openEuler
References: bsn#22
openEuler-commit: 94974bb002bd8f035e2ed2769757e3aba8d29e32
Modified-by-SEL: No


hulk inclusion
category: bugfix
bugzilla: 46904 https://gitee.com/openeuler/kernel/issues/I4Y0XO

--------------------------------

Use check_new_page to check the page to be allocated.

Signed-off-by: Liu Shixin <liushixin2@huawei.com>
Reviewed-by: Kefeng Wang <wangkefeng.wang@huawei.com>
Signed-off-by: Zheng Zengkai <zhengzengkai@huawei.com>
Signed-off-by: Guoqing Jiang <guoqing.jiang@suse.com>
---
 mm/dynamic_hugetlb.c | 29 ++++++++++++++++-------------
 mm/internal.h        |  1 +
 mm/page_alloc.c      |  2 +-
 3 files changed, 18 insertions(+), 14 deletions(-)

diff --git a/mm/dynamic_hugetlb.c b/mm/dynamic_hugetlb.c
index f5f64c4f0acf..90e2a52390b2 100644
--- a/mm/dynamic_hugetlb.c
+++ b/mm/dynamic_hugetlb.c
@@ -476,20 +476,23 @@ static struct page *__alloc_page_from_dhugetlb_pool(void)
 	 */
 	spin_lock_irqsave(&percpu_pool->lock, flags);
 
-	if (percpu_pool->free_pages == 0) {
-		int ret;
-
-		spin_lock(&hpool->lock);
-		ret = add_pages_to_percpu_pool(hpool, percpu_pool,
-						PERCPU_POOL_PAGE_BATCH);
-		spin_unlock(&hpool->lock);
-		if (ret)
-			goto unlock;
-	}
+	do {
+		page = NULL;
+		if (percpu_pool->free_pages == 0) {
+			int ret;
+
+			spin_lock(&hpool->lock);
+			ret = add_pages_to_percpu_pool(hpool, percpu_pool,
+							PERCPU_POOL_PAGE_BATCH);
+			spin_unlock(&hpool->lock);
+			if (ret)
+				goto unlock;
+		}
 
-	page = list_entry(percpu_pool->head_page.next, struct page, lru);
-	list_del(&page->lru);
-	percpu_pool->free_pages--;
+		page = list_entry(percpu_pool->head_page.next, struct page, lru);
+		list_del(&page->lru);
+		percpu_pool->free_pages--;
+	} while (page && check_new_page(page));
 	percpu_pool->used_pages++;
 	SetPagePool(page);
 
diff --git a/mm/internal.h b/mm/internal.h
index 31517354f3c7..917b86b2870c 100644
--- a/mm/internal.h
+++ b/mm/internal.h
@@ -195,6 +195,7 @@ extern void memblock_free_pages(struct page *page, unsigned long pfn,
 					unsigned int order);
 extern void __free_pages_core(struct page *page, unsigned int order);
 extern void prep_compound_page(struct page *page, unsigned int order);
+extern int check_new_page(struct page *page);
 extern void post_alloc_hook(struct page *page, unsigned int order,
 					gfp_t gfp_flags);
 extern void prep_new_page(struct page *page, unsigned int order, gfp_t gfp_flags,
diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index a72df34fa210..a27aed0b9987 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -2204,7 +2204,7 @@ static void check_new_page_bad(struct page *page)
 /*
  * This page is about to be returned from the page allocator
  */
-static inline int check_new_page(struct page *page)
+inline int check_new_page(struct page *page)
 {
 	if (likely(page_expected_state(page,
 				PAGE_FLAGS_CHECK_AT_PREP|__PG_HWPOISON)))
-- 
2.26.2

