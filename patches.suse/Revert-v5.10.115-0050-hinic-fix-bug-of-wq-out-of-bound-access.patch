From acb277b0a0e8ba70f71b441998d9ba6432dceb8b Mon Sep 17 00:00:00 2001
From: Kai Liu <kai.liu@suse.com>
Date: Thu, 12 May 2022 20:13:56 +0800
Subject: [PATCH] Revert "hinic: fix bug of wq out of bound access"
Patch-mainline: Never, revert stable patch which is added again in sorted section
References: bsn#83
Modified-by-SEL: No

This reverts commit 475237e807a2264b15772ddfd0d525b7ccc48ff8.

Signed-off-by: Kai Liu <kai.liu@suse.com>
---
 drivers/net/ethernet/huawei/hinic/hinic_hw_wq.c | 7 ++-----
 1 file changed, 2 insertions(+), 5 deletions(-)

diff --git a/drivers/net/ethernet/huawei/hinic/hinic_hw_wq.c b/drivers/net/ethernet/huawei/hinic/hinic_hw_wq.c
index f04ac00e3e70..5dc3743f8091 100644
--- a/drivers/net/ethernet/huawei/hinic/hinic_hw_wq.c
+++ b/drivers/net/ethernet/huawei/hinic/hinic_hw_wq.c
@@ -771,7 +771,7 @@ struct hinic_hw_wqe *hinic_get_wqe(struct hinic_wq *wq, unsigned int wqe_size,
 	/* If we only have one page, still need to get shadown wqe when
 	 * wqe rolling-over page
 	 */
-	if (curr_pg != end_pg || end_prod_idx < *prod_idx) {
+	if (curr_pg != end_pg || MASKED_WQE_IDX(wq, end_prod_idx) < *prod_idx) {
 		void *shadow_addr = &wq->shadow_wqe[curr_pg * wq->max_wqe_size];
 
 		copy_wqe_to_shadow(wq, shadow_addr, num_wqebbs, *prod_idx);
@@ -841,10 +841,7 @@ struct hinic_hw_wqe *hinic_read_wqe(struct hinic_wq *wq, unsigned int wqe_size,
 
 	*cons_idx = curr_cons_idx;
 
-	/* If we only have one page, still need to get shadown wqe when
-	 * wqe rolling-over page
-	 */
-	if (curr_pg != end_pg || end_cons_idx < curr_cons_idx) {
+	if (curr_pg != end_pg) {
 		void *shadow_addr = &wq->shadow_wqe[curr_pg * wq->max_wqe_size];
 
 		copy_wqe_to_shadow(wq, shadow_addr, num_wqebbs, *cons_idx);
-- 
2.35.1

