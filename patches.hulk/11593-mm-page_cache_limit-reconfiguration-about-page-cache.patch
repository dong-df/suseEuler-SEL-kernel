From 955d63aec936df0ffbb53118ab28b4c208ac8abf Mon Sep 17 00:00:00 2001
From: Chen Wandun <chenwandun@huawei.com>
Date: Mon, 29 Nov 2021 16:28:34 +0800
Subject: [PATCH] mm/page_cache_limit: reconfiguration about page cache limit
 when memory plug/unplug
Patch-mainline: Not yet, from openEuler
References: bsn#22
openEuler-commit: 955d63aec936df0ffbb53118ab28b4c208ac8abf


hulk inclusion
category: feature
bugzilla: https://gitee.com/openeuler/kernel/issues/I4HOXK

------------------------------------------

kthread and page cache limit should be reconfigured when memory
hot plug and hot unplug.

Signed-off-by: Chen Wandun <chenwandun@huawei.com>
Reviewed-by: Kefeng Wang <wangkefeng.wang@huawei.com>
Signed-off-by: Zheng Zengkai <zhengzengkai@huawei.com>
Signed-off-by: Guoqing Jiang <guoqing.jiang@suse.com>
---
 include/linux/page_cache_limit.h |  4 +++
 mm/memory_hotplug.c              |  3 +++
 mm/page_cache_limit.c            | 45 +++++++++++++++++++++++++-------
 3 files changed, 43 insertions(+), 9 deletions(-)

diff --git a/include/linux/page_cache_limit.h b/include/linux/page_cache_limit.h
index e4ef5919cb92..7906b12af947 100644
--- a/include/linux/page_cache_limit.h
+++ b/include/linux/page_cache_limit.h
@@ -17,7 +17,11 @@ int proc_page_cache_limit(struct ctl_table *table, int write,
 		void __user *buffer, size_t *lenp, loff_t *ppos);
 unsigned long __shrink_node_page_cache(int nid, gfp_t mask,
 		unsigned long nr_to_reclaim, enum page_cache_reclaim_flag flag);
+void kpagecache_limitd_stop(int nid);
+int kpagecache_limitd_run(int nid);
 #else
+static inline void kpagecache_limitd_stop(int nid) {}
+static inline int kpagecache_limitd_run(int nid) { return 0; }
 #endif
 
 #endif
diff --git a/mm/memory_hotplug.c b/mm/memory_hotplug.c
index a009b6395b02..a8f0d804a758 100644
--- a/mm/memory_hotplug.c
+++ b/mm/memory_hotplug.c
@@ -38,6 +38,7 @@
 #include <linux/rmap.h>
 
 #include <asm/tlbflush.h>
+#include <linux/page_cache_limit.h>
 
 #include "internal.h"
 #include "shuffle.h"
@@ -735,6 +736,7 @@ int __ref online_pages(unsigned long pfn, unsigned long nr_pages,
 
 	kswapd_run(nid);
 	kcompactd_run(nid);
+	kpagecache_limitd_run(nid);
 
 	writeback_set_ratelimit();
 
@@ -1491,6 +1493,7 @@ int __ref offline_pages(unsigned long start_pfn, unsigned long nr_pages)
 	if (arg.status_change_nid >= 0) {
 		kswapd_stop(node);
 		kcompactd_stop(node);
+		kpagecache_limitd_stop(node);
 	}
 
 	writeback_set_ratelimit();
diff --git a/mm/page_cache_limit.c b/mm/page_cache_limit.c
index 1581334429e1..0a3098c9bb33 100644
--- a/mm/page_cache_limit.c
+++ b/mm/page_cache_limit.c
@@ -31,18 +31,27 @@ static unsigned long get_node_total_pages(int nid)
 	return managed_pages;
 }
 
-static void setup_pagecache_limit(void)
+static void setup_node_pagecache_limit(int nid)
 {
-	int i;
 	unsigned long node_total_pages;
 
+	node_total_pages = get_node_total_pages(nid);
+	node_pagecache_limit_pages[nid] = node_total_pages * pagecache_limit_ratio / 100;
+}
+
+#define ALL_NODE (-1)
+static void setup_pagecache_limit(int nid)
+{
+	int i;
+
 	pagecache_limit_pages = pagecache_limit_ratio * totalram_pages() / 100;
 
-	for (i = 0; i < MAX_NUMNODES; i++) {
-		node_total_pages = get_node_total_pages(i);
-		node_pagecache_limit_pages[i] = node_total_pages *
-						pagecache_limit_ratio / 100;
-	}
+	if (nid != ALL_NODE)
+		setup_node_pagecache_limit(nid);
+
+	else
+		for (i = 0; i < MAX_NUMNODES; i++)
+			setup_node_pagecache_limit(i);
 }
 
 int proc_page_cache_limit(struct ctl_table *table, int write,
@@ -53,7 +62,7 @@ int proc_page_cache_limit(struct ctl_table *table, int write,
 	ret = proc_dointvec_minmax(table, write, buffer, lenp, ppos);
 
 	if (write && !ret)
-		setup_pagecache_limit();
+		setup_pagecache_limit(ALL_NODE);
 
 	return ret;
 }
@@ -72,6 +81,8 @@ void kpagecache_limitd_stop(int nid)
 		kvfree(pagecache_limitd_wait_queue[nid]);
 		pagecache_limitd_wait_queue[nid] = NULL;
 	}
+
+	setup_pagecache_limit(nid);
 }
 
 static void wakeup_kpagecache_limitd(int nid)
@@ -207,7 +218,7 @@ static int pagecache_limitd(void *arg)
 	return 0;
 }
 
-int kpagecache_limitd_run(int nid)
+static int __kpagecache_limitd_run(int nid)
 {
 	int ret = 0;
 	wait_queue_head_t *queue_head = NULL;
@@ -236,6 +247,22 @@ int kpagecache_limitd_run(int nid)
 	return ret;
 }
 
+int kpagecache_limitd_run(int nid)
+{
+	int ret;
+
+	if (nid < 0 || nid >= MAX_NUMNODES)
+		return -EINVAL;
+
+	ret = __kpagecache_limitd_run(nid);
+	if (ret)
+		return ret;
+
+	setup_pagecache_limit(nid);
+
+	return 0;
+}
+
 static int __init kpagecache_limitd_init(void)
 {
 	int nid;
-- 
2.26.2

